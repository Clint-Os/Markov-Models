{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a86a824",
   "metadata": {},
   "source": [
    "# 01 – Model Equations & Core Functions\n",
    "\n",
    "We implement the mathematical core of the **Mixed Hidden Markov Model (mHMM)**\n",
    "described in the paper:\n",
    "\n",
    "> *Handling underlying discrete variables with bivariate mixed hidden Markov models in NONMEM.*\n",
    "\n",
    "We’ll implement:\n",
    "\n",
    "1. **Emission models** – the observed data (FEV1 i.e Forced Expiratory Volume and PRO i.e Patient-reported outcomes) conditional on hidden states.  \n",
    "2. **Transition probabilities** – parameterized state-switching dynamics.  \n",
    "3. **Forward algorithm** – recursive computation of the likelihood.  \n",
    "4. **Viterbi algorithm** – decoding most probable state sequences.\n",
    "\n",
    "Later notebooks (`02_simulator.ipynb` and `03_estimation.ipynb`) will import these functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1daf50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log, exp\n",
    "from scipy.stats import multivariate_normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4647d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic and Logit transformations\n",
    "\n",
    "def logisitic(x):\n",
    "    \"\"\"Logisitic transformation\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def logit(p):  #logit is the inverse of logistic\n",
    "    \"\"\"Logit transformation\"\"\"\n",
    "    return np.log(p / (1 - p))\n",
    "\n",
    "def logsumexp(log_probs):  \n",
    "    \"\"\"Stable computation of log-sum-exp\"\"\"\n",
    "    a_max = np.max(log_probs)\n",
    "    return a_max + np.log(np.sum(np.exp(log_probs - a_max))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c991c6",
   "metadata": {},
   "source": [
    "We then build a modular bivariate Gaussian emission model for FEV1 and PRO given the hidden state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "976d7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-12  #small constant to avoid log(0)\n",
    "\n",
    "def var_to_std(var):\n",
    "    \"\"\"Convert variance to standard deviation\"\"\"\n",
    "    return np.sqrt(np.maximum(var, 0.0))\n",
    "\n",
    "class EmissionModel:\n",
    "    \"\"\"Implement the emission probability P(Y_t | S_t = s)\n",
    "    where Y_t = (FEV1_t, PRO_t) are the observed data at time t\n",
    "    and S_t = s is the hidden state at time t.\n",
    "\n",
    "    Modes (h*) used to build individual-level FEV1/PRO values.\n",
    "    IIV random effects g ~ Normal(0, x2_*)\n",
    "    Residual variances r2FEV1, r2PRO used directly in covariance\n",
    "    correlation q (state-specific) used to form covariance\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 hFEV1R, hFEV1E,\n",
    "                 x2_FEV1R=0.03, x2_FEV1E=0.03,\n",
    "                 hPROR=2.5, hPROE=0.5,\n",
    "                 x2_PROR=0.09, x2_PROE=0.09,\n",
    "                 r2_FEV1=0.015, r2_PRO=0.05,\n",
    "                 qR=-0.33, qE=-0.33,\n",
    "                 PE=0.2, PHL=10.0):\n",
    "\n",
    "        # population mode params\n",
    "        self.hFEV1R = float(hFEV1R)\n",
    "        self.hFEV1E = float(hFEV1E)\n",
    "        self.hPROR = float(hPROR)\n",
    "        self.hPROE = float(hPROE)\n",
    "\n",
    "        # IIV variances\n",
    "        self.x2_FEV1R = float(x2_FEV1R)\n",
    "        self.x2_FEV1E = float(x2_FEV1E)\n",
    "        self.x2_PROR = float(x2_PROR)\n",
    "        self.x2_PROE = float(x2_PROE)\n",
    "\n",
    "        # residual variances\n",
    "        self.r2_FEV1 = float(r2_FEV1)\n",
    "        self.r2_PRO = float(r2_PRO)\n",
    "\n",
    "        # correlations per state\n",
    "        self.qR = float(qR)\n",
    "        self.qE = float(qE)\n",
    "\n",
    "        # placebo effect params for PRO\n",
    "        self.PE = float(PE)\n",
    "        self.PHL = float(PHL)  # halflife taken to be 10 weeks\n",
    "\n",
    "    def sample_individual_effects(self, rng=None):\n",
    "        \"\"\"Sample one set of individual random effects g* (mean 0, var = x2_*)\"\"\"\n",
    "        rng = np.random.default_rng(rng)\n",
    "        g = {\n",
    "            \"gFEV1R\": rng.normal(0.0, np.sqrt(self.x2_FEV1R)),\n",
    "            \"gFEV1E\": rng.normal(0.0, np.sqrt(self.x2_FEV1E)),\n",
    "            \"gPROR\": rng.normal(0.0, np.sqrt(self.x2_PROR)),\n",
    "            \"gPROE\": rng.normal(0.0, np.sqrt(self.x2_PROE)),\n",
    "        }\n",
    "        return g\n",
    "\n",
    "    def individual_fev1(self, g, state):\n",
    "        \"\"\"\n",
    "        Compute individuals's latent FEV1 for given state as in Eq. 1 & 2\n",
    "        \"\"\"\n",
    "        FEV1_R = self.hFEV1R * np.exp(g[\"gFEV1R\"])\n",
    "        if state == 0:\n",
    "            return FEV1_R\n",
    "        else:\n",
    "            #rem for eq 2: FEV1_E = FEV1_R - hFEV1E * exp(g[\"gFEV1E\"])\n",
    "            return FEV1_R - self.hFEV1E * np.exp(g[\"gFEV1E\"]) \n",
    "        \n",
    "    def individual_pro(self, g, time, state):\n",
    "        \"\"\"\n",
    "        Compute individual's latent PRO for given state and time as in Eq. 3 & 4, including placebo effect half-life(PHL)\n",
    "        \"\"\"\n",
    "       \n",
    "        tfactor = 1.0 - self.PE * (1.0 - np.exp(-np.log(2.0) * time / self.PHL)) #time dependent placebo effect\n",
    "        PRO_R = (self.hPROR + g[\"gPROR\"]) * tfactor\n",
    "\n",
    "        if state == 0:\n",
    "            return PRO_R \n",
    "        else:\n",
    "            #rem for eq 4: PRO_E = PRO_R + hPROE + g[\"gPROE\"]\n",
    "            return PRO_R + self.hPROE + g[\"gPROE\"]\n",
    "        \n",
    "    \n",
    "    def emission_cov(self, state):\n",
    "        \"\"\"\n",
    "        Compute the emission covariance matrix (2x2) for given state\n",
    "        \"\"\"\n",
    "        q = self.qR if state ==0 else self.qE\n",
    "        covxy = q * np.sqrt(self.r2_FEV1 * self.r2_PRO)\n",
    "        cov = np.array([[self.r2_FEV1, covxy],\n",
    "                        [covxy, self.r2_PRO]])  #2x2 covariance matrix\n",
    "        return cov\n",
    "    \n",
    "\n",
    "    def logpdf(self, y, g, time, state):\n",
    "        \"\"\"\n",
    "        Compute the log probability density function (pdf) of observing y=(FEV1, PRO)\n",
    "        given individual effects g, time, and state.\n",
    "        \"\"\"\n",
    "        mu_FEV1 = self.individual_fev1(g, state)\n",
    "        mu_PRO = self.individual_pro(g, time, state)\n",
    "        mu = np.array([mu_FEV1, mu_PRO])  #mean vector\n",
    "\n",
    "        cov = self.emission_cov(state)  #covariance matrix\n",
    "\n",
    "        logpdf = multivariate_normal.logpdf(y, mean=mu, cov=cov + np.eye(2)*EPS)\n",
    "        return logpdf\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c44fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example log-probability (state=0): -7.247\n"
     ]
    }
   ],
   "source": [
    "# Instantiate emission model (example reference scenario)\n",
    "em = EmissionModel(hFEV1R=3.0, hFEV1E=0.5)\n",
    "\n",
    "# Draw one subject's random effects\n",
    "g = em.sample_individual_effects()\n",
    "\n",
    "# Simulate example observation\n",
    "time = 5  # weeks\n",
    "state = 0  # remission\n",
    "y_obs = np.array([3.2, 2.1])\n",
    "\n",
    "log_prob = em.logpdf(y_obs, g, time, state)\n",
    "print(f\"Example log-probability (state={state}): {log_prob:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08eb581",
   "metadata": {},
   "source": [
    "Transition Probabilities (Eqs 7-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c46a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransitionModel:\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the transition probabilities between Reference and Exarcebation states.\"\"\"\n",
    "    \n",
    "    def __init__(self, hpRE, gpRE, hpER, gpER, trt=0, slp=0):\n",
    "\n",
    "        \"\"\"\n",
    "        Initialize transition model with parameters:\n",
    "        hpRE: baseline logit prob of R->E\n",
    "        gpRE: IIV random effect/covariate coefficient for R->E\n",
    "        hPER: baseline logit prob of E->R\n",
    "        gpER: IIV random effect variance for E->R\n",
    "        trt, slp: treatment/slope effect covariates\n",
    "        \"\"\"\n",
    "        self.hpRE = float(hpRE)\n",
    "        self.gpRE = float(gpRE)\n",
    "        self.hpER = float(hpER)\n",
    "        self.gpER = float(gpER)\n",
    "        self.trt = float(trt)\n",
    "        self.slp = float(slp)\n",
    "\n",
    "    def transition_matrix(self):\n",
    "        \"\"\"\n",
    "        Compute the 2x2 transition probability matrix:\n",
    "        P = [[P(R->R), P(R->E)],\n",
    "             [P(E->R), P(E->E)]]\n",
    "        using logistic transformations.\n",
    "        \"\"\"\n",
    "        logit_pRE = self.hpRE + self.gpRE - (self.trt * self.slp) #remission to exarcebation\n",
    "        logit_pER = self.hpER + self.gpER + (self.slp * self.trt) #exarcebation to remission increases with drug effect\n",
    "\n",
    "        pRE = logisitic(logit_pRE)\n",
    "        pER = logisitic(logit_pER)\n",
    "\n",
    "        P = np.array([[1 - pRE, pRE],\n",
    "                      [pER, 1 - pER]])\n",
    "        return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e71b6ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix:\n",
      " [[0.549834   0.450166  ]\n",
      " [0.66818777 0.33181223]]\n"
     ]
    }
   ],
   "source": [
    "#test cell\n",
    "tm = TransitionModel(hpRE=0.1, gpRE=0.2, hpER=0.3, gpER=-0.1, trt=1, slp=0.5)\n",
    "print(\"Transition matrix:\\n\", tm.transition_matrix()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b85ef0",
   "metadata": {},
   "source": [
    "Implement Forward Algorithm to calculate total Likelihood (Lj) by summing all the probabilities of each state at each position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d006ca5",
   "metadata": {},
   "source": [
    "=> α0​(i)=P(S0​=i)×P(O0​∣S0​=i) (initialize)\n",
    "\n",
    "=> α^0​(i)=∑j​α0​(j)α0​(i)​  (scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f95ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_algorithm(obs_seq, times, init_probs, trans_mat, emission_model, g):\n",
    "    \"\"\"\n",
    "    Paramters:\n",
    "    obs_seq: array of observed data (FEV1, PRO) at each time point\n",
    "    times: array of time points corresponding to obs_seq (for placebo-time effect)\n",
    "    init_probs: initial state probabilities (array of length 2)\n",
    "    trans_mat: 2x2 transition probability matrix\n",
    "    emission_model: instance of EmissionModel to compute emission logpdf\n",
    "    g: dictionary of individual random effects\n",
    "    \"\"\"\n",
    "    T = len(obs_seq)\n",
    "    n_states = len(init_probs)\n",
    "    alpha = np.zeros((T, n_states))\n",
    "    logL = 0.0\n",
    "\n",
    "    #Initialization\n",
    "    for i in range(n_states):  #compute initial forward proba for each possible hidden state i \n",
    "        alpha[0, i] = init_probs[i] * np.exp(emission_model.logpdf(obs_seq[0], g, times[0], i)) \n",
    "    scale = np.sum(alpha[0, :]) #\n",
    "    alpha[0, :] /= scale #scaling to prevent underflow\n",
    "    logL += np.log(scale + EPS)  #add log scale to total log likelihood\n",
    "\n",
    "    #Recursion\n",
    "    for t in range(1, T):\n",
    "        for j in range(n_states):\n",
    "            emiss = np.exp(emission_model.logpdf(obs_seq[t], g, times[t], j))\n",
    "            alpha[t, j] = emiss * np.sum(alpha[t-1, :] * trans_mat[:, j])\n",
    "        scale = np.sum(alpha[t, :])\n",
    "        alpha[t, :] /= scale\n",
    "        logL += np.log(scale + EPS)\n",
    "\n",
    "    return logL #return total log likelihood "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b642fd09",
   "metadata": {},
   "source": [
    "Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a54a7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs_seq, init_probs, trans_mat, emission_model, g, times):\n",
    "    \"\"\"\n",
    "    COmpute most probable hidden state sequence. The most probable\n",
    "    sequence is obtained when the likelihood of a sequence ceases to increase\n",
    "    \"\"\"\n",
    "    T = len(obs_seq)\n",
    "    n_states = len(init_probs)\n",
    "    delta = np.zeros((T, n_states))\n",
    "    psi = np.zeros((T, n_states), dtype=int)\n",
    "\n",
    "    # Initialization\n",
    "    for i in range(n_states):\n",
    "        delta[0, i] = np.log(init_probs[i] + EPS) + emission_model.logpdf(obs_seq[0], g, times[0], i)\n",
    "        \n",
    "\n",
    "    # Recursion\n",
    "    for t in range(1, T):\n",
    "        for j in range(n_states):\n",
    "            seq_probs = delta[t-1, :] + np.log(trans_mat[:, j] + EPS)\n",
    "            psi[t, j] = np.argmax(seq_probs)\n",
    "            delta[t, j] = np.max(seq_probs) + emission_model.logpdf(obs_seq[t], g, times[t], j)\n",
    "    \n",
    "    #Backtracking to find most probable state sequence\n",
    "    states = np.zeros(T, dtype=int)\n",
    "    states[-1] = np.argmax(delta[-1, :])\n",
    "    for t in reversed(range(T-1)):\n",
    "        states[t] = psi[t+1, states[t+1]]\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43763e3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EmissionModel.logpdf() missing 2 required positional arguments: 'time' and 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m g \u001b[38;5;241m=\u001b[39m em\u001b[38;5;241m.\u001b[39msample_individual_effects()\n\u001b[1;32m      9\u001b[0m times \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(obs_seq)) \n\u001b[0;32m---> 10\u001b[0m v_states \u001b[38;5;241m=\u001b[39m \u001b[43mviterbi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoded Viterbi states:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, v_states)\n",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m, in \u001b[0;36mviterbi\u001b[0;34m(obs_seq, init_probs, trans_mat, emission_model, g, times)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Initialization\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_states):\n\u001b[0;32m---> 13\u001b[0m     delta[\u001b[38;5;241m0\u001b[39m, i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(init_probs[i] \u001b[38;5;241m+\u001b[39m EPS) \u001b[38;5;241m+\u001b[39m \u001b[43memission_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_seq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Recursion\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, T):\n",
      "\u001b[0;31mTypeError\u001b[0m: EmissionModel.logpdf() missing 2 required positional arguments: 'time' and 'state'"
     ]
    }
   ],
   "source": [
    "#SANITY CHECK\n",
    "\n",
    "T = 20\n",
    "obs_seq = np.random.normal(size=(T, 2))  #random observations\n",
    "init_probs = np.array ([0.7, 0.3]) #initial state probabilities\n",
    "trans_mat = tm.transition_matrix() \n",
    "\n",
    "g = em.sample_individual_effects()\n",
    "times = np.arange(len(obs_seq)) \n",
    "v_states = viterbi(obs_seq, init_probs, trans_mat, em, g, times)\n",
    "print(\"Decoded Viterbi states:\\n\", v_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad4ed3",
   "metadata": {},
   "source": [
    "## Summary of our notebook:\n",
    "\n",
    "We have implemented:\n",
    "- Logistic / logit helpers  \n",
    "- Emission model (Eqs. 1–6)  \n",
    "- Transition probabilities (Eqs. 7–10)  \n",
    "- Forward algorithm (Eq. 11)  \n",
    "- Viterbi decoding  \n",
    "\n",
    "Next:  \n",
    "we will use **`02_simulator.ipynb`** generate synthetic FEV1–PRO trajectories using these components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb4e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3adf3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267a231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mhmm_env)\n",
   "language": "python",
   "name": "mhmm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
